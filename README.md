# Databrincks
Convertendo os arquivos em csv para parquet e os envie para processing zone 
Dataset

Usaremos esse dataset https://www.kaggle.com/nhs/general-practice-prescribing-data

# ler arquivos vários arquivos csv do dbfs com spark
# printSchema
# Lendo todos os arquivos .csv do diretório bigdata (>4GB)
# imprime as 10 primeiras linhas do dataframe
# conta a quantidade de linhas
# conta a quantidade de linhas
# Converte para formato parquet
# lendo arquivos parquet
# atente para a velocidade de leitura
# conta a quantidade de linhas do dataframe
